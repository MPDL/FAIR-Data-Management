---
title: "4) Data management plans"
link-external-newwindow: true
---

## Overview

As the previous sections have shown, data management is a broad topic encompassing various aspects. Therefore, good planning is essential to effectively manage all these aspects according to the [FAIR principles](https://www.go-fair.org/fair-principles/). A valuable tool for this purpose is a (research) data management plan (DMP). This section provides an overview of the components of a DMP, offers tips on creating one, and introduces helpful tools. We conclude with a practical exercise where you will work on a small section of a DMP.

## General information

A data management plan is a written document that describes the data you expect to acquire or generate during the course of a research project, how you will manage, describe, analyze, and store the data, and what mechanisms you will use at the end of your project to share and preserve your data. Thus, a data management plan accompanies and guides you throughout the project and encompasses all phases that research data go through in a project. Following the motto “start early, refine often”, creating a DMP at the beginning of your project enables it to be a living document that evolves alongside your research. Begin with basic information and enrich the document as your project progresses. Also, it is not required to answer all questions; stick to those relevant to your data. DMPs apply to any research project, from a PHD thesis to large collaborative research projects.

## Components of a DMP

Throughout a project, there are different processing stages regarding the data. You can illustrate the process as a life cycle with the following stages[^2]:  

[![](\images\RD-Lifecycle.png){width=80%}](https://www.fdm-bayern.org/forschungsdatenmanagement/#fd-lebenszyklus)

[^2]: based on: [https://www.fdm-bayern.org/forschungsdatenmanagement/#fd-lebenszyklus](https://www.fdm-bayern.org/forschungsdatenmanagement/#fd-lebenszyklus)

A data management plan covers all stages of the data life cycle. Therefore, one can assign questions to each stage. By addressing these questions, you create an effective DMP:

- What data will be collected, and where do they come from?
- Which metadata should be used to describe the data?
- Where should the data be stored? During the project phase? After the project?
- What is about Open Data? Do you plan to publish the data?
- Is sufficient staff provided? Does your project require special infrastructure?
- How do you ensure the quality of your data?
- Does your project process personal or sensitive data? What law will be applied? Are there ethnic aspects you need to consider?
- Please note that this list is incomplete, and the questions may vary depending on your discipline and data specifics.

::: {.callout-note}
## Excursion: Published DMPs

To gain more practical insight, it may be helpful to look at published DMPs. You can find them on different repositories, e.g. [Zenodo](https://zenodo.org/search?q=DMP&l=list&p=1&s=10&sort=bestmatch). 

:::

## Example: Data storage and security

In this section, we approach a DMP from a practical perspective: DMPs are typically divided into different sections, e.g. based on the data lifecycle. In the following, we will look at the section "Data storage and security" of a DMP template, discuss the questions, and provide example answers. Before we start with this, we give some background knowledge on data storage and security. (If you already feel comfortable with it, you can skip this part.) 

Regarding data storage and security, the following three "S" encompass the topic: safe - secure - sustainable. Now, we dive into the main principles:

### Safe

Safety focuses on the protection of data against loss of physical data.[^7] Therefore, establish a regular backup routine to ensure your data's safety and recoverability. This involves creating copies of your data at specified times and storing them separately from the originals, ideally adhering to the 3-2-1 rule (see below). Consider using external hard drives or USB sticks for local backups. Additionally, if your institution offers backup systems like [LRZ cloud storage](https://doku.lrz.de/cloud-storage-kurzbeschreibung-11476147.html?showLanguage=en_US) or [LRZ Sync+Share](https://syncandshare.lrz.de/login), you can store your data there where they have automated backup mechanisms. Another synched storage is [Keeper](https://keeper.mpdl.mpg.de/accounts/login/?next=/), a service available for all Max Planck employees.

::: {.callout-warning}
## 3-2-1 rule

Maintain three copies of your data on two different storage mediums (e.g. local storage and external hard drive), with one copy stored in a remote location. A remote copy can be stored in a cloud or kept in your office. 
:::

Remember, your backups should encompass your data files and include software applications if necessary. This ensures a comprehensive recovery if needed.[^3]

For larger files exceeding 100 GB, consider services like GigaMove, which allows for efficient file sharing. For long-term data preservation with advanced security features, explore [EUDAT B2ACCESS](https://b2access.eudat.eu/home/) – you can find more information about EUDAT services on their [website](https://eudat.eu/catalogue).

[^3]: based on: [https://www.forschungsdaten.info/themen/speichern-und-rechnen/datensicherheit-und-backup/](https://www.forschungsdaten.info/themen/speichern-und-rechnen/datensicherheit-und-backup/)
[^7]: based on: [https://www.baramundi.com/de-de/blog/artikel/unterschied-safety-security/](https://www.baramundi.com/de-de/blog/artikel/unterschied-safety-security/)

### Secure

To protect data against unauthorized access and data misuse is one of the main goals of security.[^7] We recommend using access control mechanisms and encryption to prevent unauthorized access to the data and protect sensitive information. 

Confidential data is sensitive information that could cause harm if disclosed, such as details about endangered species, vulnerable archaeological sites, or personal information. Personal data is subject to strict privacy laws and requires secure handling. To protect both types of data, it is crucial to minimize the risk of identification through techniques like pseudonymization or anonymization. 

Additionally, strong password protection using reliable password management tools is essential to prevent unauthorized access.[^4]

[^4]: based on: [https://doi.org/10.17605/OSF.IO/GDQ93](https://doi.org/10.17605/OSF.IO/GDQ93) and [https://www.forschungsdaten.info/themen/speichern-und-rechnen/datensicherheit-und-backup/](https://doi.org/10.17605/OSF.IO/GDQ93)

### Sustainable 

Data sustainability refers to data that persists across technological and human evolution.[^8] Concretely, this means choosing file formats that are unlikely to become obsolete and ensuring the long-term readability and accessibility of your data. For more details on this topic, revisit Chapter 1: organization/file formats (*Link to data organisation/file formats*).

[^8]: based on: [https://doi.org/10.1016/j.infoandorg.2023.100449](https://doi.org/10.1016/j.infoandorg.2023.100449)

### Questions in the DMP 

These questions are part of the [RDMO](dmp.qmd#dmp-tool-rdmo) template, section "Data usage / Data storage and security" and "Data usage / Interoperability". For each question, we will provide you with example answers. These answers do not rely on any existing project. Also, the data and some tools (e.g. software) are made up. The example answers are based on the information in this [example DMP](https://gitlab.rrze.fau.de/cdi/labs/literacy/proposal-self-service/-/blob/main/RDMO/ERC/ERC_Example.md). 

::: {.callout-important title="Example data" collapse="true"}

- **Dataset "Simulations of neural signal transmission"**: The simulations use the open-source “QuantumNeuroBrain” (made up) software suite. We determine potentials and signals for various environments. The simulations vary the environment parameters (ion concentrations, temperature, …) and consider eight different models for the transduction mechanism proposed in the literature (also not relying on actual literature research). The simulations themselves follow from input files (for models, parameters, etc.) and configuration files that capture the used settings in software and hardware. The simulation output is further analyzed and forms the basis for illustrative images. Input, configuration files, output and derived data, such as images, are intimately connected and are considered a single diverse dataset.
- **Dataset "EEG measurements"**: This dataset includes high-resolution EEG measurements from up to 100 probands. Additional measurements will accompany the measurements to determine the environmental conditions (see previous dataset). The measurements will be performed using a Neuro++ machine (made up), allowing for state-of-the-art sensitivity. Existing measurements will supplement the dataset from a local neuroscience group. We use the open-source tool EEGalyse (made up) to analyze and visualize the results.
:::

**Safe**:

- How and how often will backups of the data be created? (This question refers to backups while the data is being worked with only, not long-term preservation.)

::: {.callout-important title="Answer for example data" collapse="true"}

- **Dataset "Simulations of neural signal transmission"**: While all data are initially stored on local servers in the research institute, all data that pass the initial quality checks are additionally transferred to servers of the university computing centre. Here, automatic backup services are available daily.
- **Dataset "EEG measurements"**: All data are stored on local servers in the research institute. The RAID system provides redundancy, and all data are backed up daily. Fully anonymized data are also stored on IT centre servers to add a layer of redundancy.

:::

- Who is responsible for the backups? (This question refers to backups while the data is being worked with only, not long-term preservation.)

::: {.callout-important title="Answer for example data" collapse="true"}

- **Dataset "Simulations of neural signal transmission"**: All project members themselves store their data on local servers in the research institute. If the data passes the initial quality checks, all researchers transfer their data to the university computing centre.
- **Dataset "EEG measurements"**: All project members themselves store their data on local servers in the research institute. The backup is then done automatically. Furthermore, the research data manager transfers the fully anonymized data to the IT centre. 

:::

**Secure**: 

- Who is allowed to access the dataset (e.g. project members, partners of the project, only in-house, external partners)?

::: {.callout-important title="Answer for example data" collapse="true"}

- **Dataset "Simulations of neural signal transmission"**: Only project members are allowed to access the data.
- **Dataset "EEG measurements"**: Only persons who are part of the EEG group of the project team are allowed to access the sensitive data. All folders are, therefore, password-protected. A detailed list of the persons who can access the data are stored in the project filesystem. Once the data is anonymized, the research manager transfers it to the IT centre, where the IT centre staff and all project members can access the data.

:::

- Which measures or provisions are in place to ensure data security (e.g. protection against unauthorized access, data recovery, transfer of sensitive data)?

::: {.callout-important title="Answer for example data" collapse="true"}

- **Dataset "Simulations of neural signal transmission"**: 
  - Protection against unauthorized access: detailed access and rights management via the university IDM system
  - Data recovery - backups: Automated backups to university computing centre servers

- **Dataset "EEG measurements"**:
   - Protection against unauthorized access: detailed access and rights management via the university IDM system, additional password protection of sensitive data 
   - Data robustness - encryption: transfer of data between systems only in encrypted form
   - Data recovery - backups: Each encrypted and fully anonymized dataset is backed up by IT centre servers. The local secure RAID system provides redundancy for sensitive data during all stages of data handling.
   - Sensitive data - anonymization or pseudonymization: access to sensitive (not fully anonymous) data is only possible for the EEG group members and on a computer physically located in the rooms of the research group
   - Other: The research manager will ensure that all group members are comfortable with the established data handling procedures, particularly regarding sensitive information, as well as using the backup service and documentation of all data handling and versioning steps.

:::

**Sustainable**:

- Is this dataset interoperable, e.g. allowing data exchange and reuse between researchers, institutions, organizations, countries, etc.?

  - [ ] The dataset adheres to standardized formats: …
  - [ ] The dataset is usable with available (open) software applications or software applications that are established and widely used in the respective community: …
  - [ ] The dataset can easily be re-combined with different datasets from different origins: …
  - [ ] Other aspects in terms of interoperability: …

::: {.callout-important title="Answer for example data" collapse="true"}

- **Dataset "Simulations of neural signal transmission"**: 
  
  - [X] Standardized formats: Input and simulation output are stored in CSV format. Derived datasets, such as cleansed or aggregated data from multiple simulations and statistical analyses, are stored in standard CSV formats. All illustrative images created from the data are stored as jpg. Each data file is accompanied by a ReadMe (plain text) file that provides information on the structure of the associated data file, such as column descriptions, units, software version, initial configuration, etc.
  - [X] Usable with available (open) /established, widely used software applications: Since all files use standardized formats (see summary section - not available here), no special software is needed.
  - [X] Re-combination with different datasets from different origins:  Notebooks and scripts are provided that can be used to retrace the more involved analysis steps and include other data. The scripts can be found on GitHub [Link to group Git]. The notebooks and the scripts require no specific tool beyond basic and free software (python, emacs, …).
  - [ ] Other aspects in terms of interoperability: -

- **Dataset "EEG measurements"**:

  - [X] Standardized formats: The created EEG data records are converted to and initially stored as BrainVision Core Data Format triples (.vhdr, .vmrk, .eeg). Additional information, such as information extracted from the manufacturer-provided data files, is recorded as JSON files. The data will automatically be transformed to the EEG-BIDS standard, which allows for combination with the existing EEG dataset.
  - [X] Usable with available (open) /established, widely used software applications: Since all files use established and highly standardized formats, the data can be used in the scientific community. The needed software is broadly available, and open-source/free solutions exist.
  - [X] Re-combination with different datasets from different origins: Reusing the data in other research contexts requires the entire dataset (pre-anonymization), which can only be made available upon detailed ethical approval.
  - [ ] Other aspects in terms of interoperability: -
  
:::

## Why is a DMP helpful?

Creating a DMP may seem like a lot of work, but it also benefits you and your research:

-   **Enhanced Organization**: A DMP ensures your data is well-documented, organized, and easily accessible throughout the project.
-   **Improved Reproducibility**: Clear documentation promotes transparency and facilitates replication of your research findings.
-   **Efficient Data Sharing**: A DMP helps preparing your data for publication and therefore simplifies data sharing once the project ends.

As mentioned, a DMP addresses crucial technical, organizational, legal, and financial considerations for your project right from the beginning and provides a comprehensive overview of all potential data management tasks. A DMP structures your workflow and builds the base for optimizations. Also, it supports your own good scientific work by ensuring your data is complete, accurate and trustworthy.

Furthermore, a DMP can be part of applications and reports to third-party-funded projects. When applying for, submitting a DMP may be mandatory (e.g. DFG, DMBF or ERC)funding. Beyond that, more and more institutions adopt guidelines for handling research data. You can find an overview of universities in Bavaria with a research data policy [here](https://www.fdm-bayern.org/policies/). 

In conclusion, a DMP is a helpful tool that streamlines your workflow and supports you in fostering research integrity.

::: {.callout-note}
## Excursion: Funder requirements

Many funding agencies ask for information on handling research data. The following table[^5] provides an overview of the requirements of German and European funding agencies:

| Funder | DMP demanded? | Submission on application? | Content | Updates?  |
|--------|---------------|----------------------------|---------|----------|
| European Commission, Horizon Europe            | Yes                               |      No, first plan within the first 6 weeks of the project   | Contents of the [Horizon Europe DMP template](https://ec.europa.eu/info/funding-tenders/opportunities/docs/2021-2027/common/agr-contr/general-mga_horizon-euratom_en.pdf); [Information and template for ERC grants](https://erc.europa.eu/sites/default/files/document/file/ERC_info_document-Open_Research_Data_and_Data_Management_Plans.pdf) | Update, if significant changes occur and at the end of the project | 
| German Research Foundation (DFG)            | Information on the handling of research data                |     Yes | Contents of the [DFG Guidelines on the Handling of Research Data](https://www.dfg.de/en/basics-topics/basics-and-principles-of-funding/research-data) | No |
| German Federal Ministry of Education and Research (BMBF)                     | Plan sometimes required, depending on the programme      |      If required, yes | Content depends on the respective programme; Educational research: Checklist (in German) | Depends on the programme |
| Volkswagen Stiftung (VW Foundation)     | Yes   | Yes |  Template for a [Base-DMP](https://www.volkswagenstiftung.de/de/faqservice#download_formulare_berichte)    |  No  |

[^5]: based on: [https://doi.org/10.5281/zenodo.5773203](https://doi.org/10.5281/zenodo.5773203)

:::

## DMP tool: RDMO

Different software is used to streamline the DMP creation process, simplify workflows, and empower collaborative work.

::: {.callout-warning title="DMP Tool vs. repository"}
It is essential to clarify the difference between a DMP tool and a repository: A DMP tool is a planning tool where you gather information about research data management in general, e.g. about the collection, description, etc. You can also use it as a documentation tool. A repository whereas is a platform where you can store and publish your data. A DMP tool does not store your research data; instead, it is a project management tool that helps you (and others) keep track of your research data management.
:::

One of these tools is [Research Data Management Organiser (RDMO)](https://rdmorganiser.github.io/). RDMO is an [open-source](https://github.com/rdmorganiser) online tool designed to create, store and print your DMP. It supports you in planning projects and administrating data management tasks throughout the whole data lifecycle. The tool is the outcome of a project co-funded by the German Research Foundation (DFG) between 2015 and 2020. The tool can be constantly developed and optimized thanks to the large and active user community. The LMU University Library and the Max Planck Digital Library offer instances of the web-based software on their servers. Register using your email or ORCID id for LMU ([LMU RDMO](https://rdmo.ub.uni-muenchen.de/)) or your MPG login (Shibboleth) for MPG ([MPG RDMO](https://rdmo.mpdl.mpg.de/)).

Key features of RDMO:

-   **Templates and guidance**: To create a DMP (called a project in RDMO), choose one of the pre-built templates that are designed as questionnaires. The questions highlight the aspects we discussed [earlier](dmp.qmd#components-of-a-dmp) and guide you step-by-step through the creation process. The questionnaires are based on the requirements of different research funding agencies, e.g., the German Research Foundation (DFG). 
-   **Collaboration-friendly**: It is possible to work collaboratively on one data management plan as a team. Therefore, RDMO supports different roles for the project members: visitor, author, manager and owner. The owner can edit and delete the project, whereas a visitor has read-only rights. 
-   **Import and export**: Furthermore, RDMO offers import and export functionalities, providing you with flexibility. A DMP can be exported to formats like PDF, XML, or Markdown. The exported document provides a good guide for internal documentation and could be a suitable tool for reporting to the funding agency.  
-   **Version control**: RDMO stores only the current version of a DMP, but the "Snapshot" feature allows you to manually track changes and revert to previous versions, giving you full control over your data management plan. 

Further information on the features of RDMO can be found here: [RDMO Quick Start Guide by LMU University Library (Download, PDF)](https://rdmo.ub.uni-muenchen.de/doc/Quick_Start_Guide_RDMO.pdf) and [Quick Start to RDMO for MPG](https://rdmo.mpdl.mpg.de/quickstart/).

::: {.callout-note}
## Excursion: Further DMP tools

In addition to RDMO, a variety of DMP tools exist. The following table[^1] provides an overview of discipline-agnostic DMP tools that are freely available online:

| Name | Provider | Templates |
|---------|-----|------|------|
| [ARGOS](https://argos.openaire.eu/home)               | OpenAIRE, EUDAT                               |      [CHIST-ERA](https://www.chistera.eu/)   |
| [DMPonline](https://dmponline.dcc.ac.uk/)             | Digital Curation Center (DCC)                 |      European programs (e.g. ERC, Horizon Europe), funding agencies from different European countries, mainly the UK, DDC template   |
| [DMPTool](https://dmptool.org/)                       | University of California, California Digital Library      |      mostly US funding agencies, DCC template |
| [Data Stewardship Wizard](https://ds-wizard.org/)     | [ELIXIR CZ](https://www.elixir-czech.cz/) / [ELIXIR NL](https://www.dtls.nl/elixir-nl/)    |  Horizon Europe, Horizon 2020, Science Europe, [maDMP](https://github.com/RDA-DMP-Common/RDA-DMP-Common-Standard)    |
| [GFBio DMPT](https://dmp.gfbio.org/)     | GFBio    |  -    |

: Overview of DMP tools

[^1]: based on: [https://forschungsdaten.info/themen/informieren-und-planen/datenmanagementplan/](https://forschungsdaten.info/themen/informieren-und-planen/datenmanagementplan/).

:::

::: callout-tip
# Task 4: (~20 min)
If you do not have a RDMO account, please register now. Either use the [LMU RDMO](https://rdmo.ub.uni-muenchen.de/) (register using your email or ORCID id) or [MPG RDMO](https://rdmo.mpdl.mpg.de/) (MPG login (Shibboleth)). Login and create a new project using the **RDMO template**. 

Answer the questions for a subset of the following section(s) for the dataset you previously worked on:

- Content classification / Datasets
- Content classification / Re-use
- Technical classification / Formats
- Data usage / Data organization 
- Data usage / Data sharing and re-use
- Metadata and referencing / Metadata

You can summarize the outcome of the previous tasks and discuss your thoughts.  
:::

:::{.callout-important collapse="true"}
## Solution
We do not provide a solution for this task as it summarizes the previous tasks. Also, note that there is no correct DMP. Try to be as precise as possible and provide detailed information on your project and research data. Depending on your data and discipline, some questions may be obsolete and do not need to be answered.   
:::